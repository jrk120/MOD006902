{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c6cb01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary modules\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import col, when, lag, round, sqrt, pow, sum as sum_func, max as max_func,row_number, lit, min as min_func, abs\n",
    "from pyspark.sql.types import StructType, StructField, LongType, StringType, BooleanType, DoubleType, IntegerType\n",
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2597fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create spark session\n",
    "spark = SparkSession.builder.appName(\"Formation insights\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e8d8e76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/06 15:02:47 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "#Select only desired columns and apply schema\n",
    "schema = StructType([\n",
    "    StructField(\"gameId\", LongType(), True),\n",
    "    StructField(\"playId\", LongType(), True),\n",
    "    StructField(\"nflId\", DoubleType(), True),\n",
    "    StructField(\"frameId\", LongType(), True),\n",
    "    StructField(\"x\", DoubleType(), True),\n",
    "    StructField(\"y\", DoubleType(), True),\n",
    "    StructField(\"frameType\", StringType(), True)\n",
    "])\n",
    "\n",
    "#Merge all the tracking data into one dataframe.\n",
    "trackingDf = spark.read.schema(schema).parquet(\"data/tracking/\").cache()\n",
    "\n",
    "#Filter and select tracking data just before the snap - to determine if there is any pre-snap motion\n",
    "snapEventsDf = trackingDf.filter(col(\"frameType\") == \"SNAP\").groupby(\"gameId\", \"playId\").agg(min_func(\"frameId\").alias(\"snapEvent\"))\n",
    "\n",
    "#Join with full data to get last second before snap, using the last 10 frames (update rate of 0.1 seconds)\n",
    "presnapDf = trackingDf.join(snapEventsDf, [\"gameId\", \"playId\"]).filter(col(\"frameId\") < col(\"snapEvent\")).filter(col(\"frameId\") >= (col(\"snapEvent\") - 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b5f5ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/06 15:02:47 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/06 15:02:48 WARN MemoryStore: Not enough space to cache rdd_4_1 in memory! (computed 65.8 MiB so far)\n",
      "25/06/06 15:02:48 WARN MemoryStore: Not enough space to cache rdd_4_0 in memory! (computed 65.8 MiB so far)\n",
      "25/06/06 15:02:54 WARN MemoryStore: Not enough space to cache rdd_4_2 in memory! (computed 101.1 MiB so far)\n",
      "25/06/06 15:02:58 WARN MemoryStore: Not enough space to cache rdd_4_4 in memory! (computed 101.0 MiB so far)\n",
      "25/06/06 15:02:58 WARN MemoryStore: Not enough space to cache rdd_4_5 in memory! (computed 42.7 MiB so far)\n",
      "25/06/06 15:03:02 WARN MemoryStore: Not enough space to cache rdd_4_7 in memory! (computed 101.1 MiB so far)\n",
      "25/06/06 15:03:06 WARN MemoryStore: Not enough space to cache rdd_4_0 in memory! (computed 42.7 MiB so far)\n",
      "25/06/06 15:03:06 WARN MemoryStore: Not enough space to cache rdd_4_8 in memory! (computed 101.1 MiB so far)\n",
      "25/06/06 15:03:10 WARN MemoryStore: Not enough space to cache rdd_4_1 in memory! (computed 65.8 MiB so far)\n",
      "25/06/06 15:03:10 WARN MemoryStore: Not enough space to cache rdd_4_2 in memory! (computed 65.8 MiB so far)\n",
      "25/06/06 15:03:13 WARN MemoryStore: Not enough space to cache rdd_4_4 in memory! (computed 101.0 MiB so far)\n",
      "25/06/06 15:03:15 WARN MemoryStore: Not enough space to cache rdd_4_5 in memory! (computed 101.0 MiB so far)\n",
      "25/06/06 15:03:18 WARN MemoryStore: Not enough space to cache rdd_4_7 in memory! (computed 101.1 MiB so far)\n",
      "25/06/06 15:03:18 WARN MemoryStore: Not enough space to cache rdd_4_8 in memory! (computed 42.7 MiB so far)\n",
      "25/06/06 15:03:21 WARN MemoryStore: Not enough space to cache rdd_4_0 in memory! (computed 65.8 MiB so far)\n",
      "25/06/06 15:03:22 WARN MemoryStore: Not enough space to cache rdd_4_1 in memory! (computed 152.0 MiB so far)\n",
      "25/06/06 15:03:23 WARN MemoryStore: Not enough space to cache rdd_4_3 in memory! (computed 101.1 MiB so far)\n",
      "25/06/06 15:03:23 WARN MemoryStore: Not enough space to cache rdd_4_2 in memory! (computed 152.1 MiB so far)\n",
      "25/06/06 15:03:25 WARN MemoryStore: Not enough space to cache rdd_4_7 in memory! (computed 42.7 MiB so far)\n",
      "25/06/06 15:03:26 WARN MemoryStore: Not enough space to cache rdd_4_8 in memory! (computed 65.8 MiB so far)\n",
      "25/06/06 15:03:27 WARN MemoryStore: Not enough space to cache rdd_4_0 in memory! (computed 65.8 MiB so far)\n",
      "25/06/06 15:03:29 WARN MemoryStore: Not enough space to cache rdd_4_2 in memory! (computed 101.1 MiB so far)\n",
      "25/06/06 15:03:31 WARN MemoryStore: Not enough space to cache rdd_4_4 in memory! (computed 101.0 MiB so far)\n",
      "25/06/06 15:03:32 WARN MemoryStore: Not enough space to cache rdd_4_6 in memory! (computed 101.1 MiB so far)\n",
      "25/06/06 15:03:32 WARN MemoryStore: Not enough space to cache rdd_4_7 in memory! (computed 101.1 MiB so far)\n",
      "25/06/06 15:03:33 WARN MemoryStore: Not enough space to cache rdd_4_8 in memory! (computed 27.3 MiB so far)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-------+-----+-----+-----------+---------+--------+---------+--------------+------------------+------------+\n",
      "|  nflId|    gameId|playId|frameId|    x|    y|  frameType|snapEvent|position|isOffence|yardlineNumber|          distance|max(frameId)|\n",
      "+-------+----------+------+-------+-----+-----+-----------+---------+--------+---------+--------------+------------------+------------+\n",
      "|52542.0|2022092511|  1986|     16|15.24|36.28|BEFORE_SNAP|       26|      FS|    false|            13|              2.24|          25|\n",
      "|52542.0|2022092511|  1986|     17|15.31|36.31|BEFORE_SNAP|       26|      FS|    false|            13|2.3100000000000005|          25|\n",
      "|52542.0|2022092511|  1986|     18|15.37|36.34|BEFORE_SNAP|       26|      FS|    false|            13| 2.369999999999999|          25|\n",
      "|52542.0|2022092511|  1986|     19|15.42|36.36|BEFORE_SNAP|       26|      FS|    false|            13|              2.42|          25|\n",
      "|52542.0|2022092511|  1986|     20|15.47|36.37|BEFORE_SNAP|       26|      FS|    false|            13|2.4700000000000006|          25|\n",
      "+-------+----------+------+-------+-----+-----+-----------+---------+--------+---------+--------------+------------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "#Read in columns of interest from players data source \n",
    "schema = StructType([\n",
    "    StructField(\"nflId\", LongType(), True), \n",
    "    StructField(\"position\", StringType(), True)\n",
    "])\n",
    "\n",
    "#Read in players datasource and apply schema\n",
    "playersDf = spark.read.schema(schema).parquet(\"data/players.parquet\").cache()\n",
    "\n",
    "#Add positions column, through a join\n",
    "presnapDf = presnapDf.join(playersDf.select(\"nflId\", \"position\"), on=\"nflId\", how=\"left\")\n",
    "\n",
    "playersDf.unpersist()\n",
    "\n",
    "#Position classifications\n",
    "offensivePositions = [\"QB\", \"RB\", \"FB\", \"HB\", \"WR\", \"TE\", \"LT\", \"LG\", \"C\", \"RG\", \"RT\"]\n",
    "defensivePositions = [\"CB\", \"S\", \"FS\", \"SS\", \"MLB\", \"OLB\", \"ILB\", \"LB\", \"DT\", \"DE\", \"NT\", \"DB\"]\n",
    "\n",
    "#Create a classifier column for if the player is on offence or defence\n",
    "presnapDf = presnapDf.withColumn(\"isOffence\",when(col(\"position\").isin(*offensivePositions), True).when(col(\"position\").isin(*defensivePositions), False).otherwise(lit(None)).cast(BooleanType()))\n",
    "\n",
    "safetyDf = presnapDf.filter(col(\"position\").isin([\"SS\", \"FS\"]))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"gameId\", LongType(), True),\n",
    "    StructField(\"playId\", LongType(), True),\n",
    "    StructField(\"yardlineNumber\", LongType(), True)\n",
    "])\n",
    "\n",
    "playsDf = spark.read.schema(schema).parquet(\"data/plays.parquet\").cache()\n",
    "\n",
    "safetyDf = safetyDf.join(playsDf.select(\"gameId\", \"playId\", \"yardlineNumber\"), on = [\"gameId\", \"playId\"], how = \"left\")\n",
    "\n",
    "safetyDf = safetyDf.withColumn(\"distance\", abs(col(\"yardlineNumber\") - col(\"x\")))\n",
    "\n",
    "frameGroupByDf = safetyDf.groupBy(\"nflId\", \"gameId\", \"playId\").agg(max_func(\"frameId\"))\n",
    "\n",
    "safetyDf = safetyDf.join(frameGroupByDf, on = [\"nflId\",\"gameId\", \"playId\"], how = \"inner\")\n",
    "\n",
    "safetyDf.show(5)\n",
    "\n",
    "#Drop redundant columns\n",
    "presnapDf = presnapDf.drop(\"frameId\", \"frameType\", \"snapEvent\", \"position\")\n",
    "\n",
    "presnapDf = presnapDf.withColumn(\"sequenceId\", monotonically_increasing_id())\n",
    "sparkWindow = Window.partitionBy(\"gameId\", \"playId\", \"nflId\").orderBy(\"sequenceId\")\n",
    "\n",
    "#Add orderId using row number (for later sorting)\n",
    "presnapDf = presnapDf.withColumn(\"orderId\", row_number().over(sparkWindow))\n",
    "\n",
    "presnapDf = presnapDf.withColumn(\"prevX\", round(lag(\"x\").over(sparkWindow), 2))\n",
    "presnapDf = presnapDf.withColumn(\"prevY\", round(lag(\"y\").over(sparkWindow), 2))\n",
    "\n",
    "#Calculate cumulative distance\n",
    "presnapDf = presnapDf.withColumn(\"cumulativeDistance\", round(when(col(\"prevX\").isNull() | col(\"prevY\").isNull(), 0.0).otherwise(sqrt(pow(col(\"x\") - col(\"prevX\"), 2) + pow(col(\"y\") - col(\"prevY\"), 2))),5))\n",
    "\n",
    "#Sum all the movement values - this gives total distance moved in a second\n",
    "playerMotion = presnapDf.groupBy(\"gameId\", \"playId\", \"nflId\", \"isOffence\").agg(sum_func(\"cumulativeDistance\").alias(\"distanceMoved\"))\n",
    "\n",
    "presnapDf.unpersist()\n",
    "\n",
    "#Using a threshold of 2 yards in the 1 second time frame, determine if the player was in motion\n",
    "playerMotion = playerMotion.withColumn(\"motion\", col(\"distanceMoved\") > 2)\n",
    "\n",
    "#Determine if any player on each side was in motion\n",
    "playMotion = playerMotion.groupBy(\"gameId\", \"playId\", \"isOffence\").agg(max_func(\"motion\").alias(\"isMotion\"))\n",
    "\n",
    "#Create final result\n",
    "playMotion = playMotion.select(\"gameId\", \"playId\", \"isOffence\", \"isMotion\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
